{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#import ipdb\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "from matplotlib import lines\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "EXP_NAME = \"logs\"\n",
    "\n",
    "MAX_ROUNDS = 70\n",
    "MAX_YVAL = 5\n",
    "\n",
    "RESULTS_DIR = os.path.join( os.getcwd(),'results')\n",
    "\n",
    "headers = ['time', 'elapsed', 'remotehost', 'code/status','bytes','method','URL','rfc931', 'peerstatus/peerhost','type'] \n",
    "headers = ['time', 'elapsed', 'bytes']\n",
    "dtypes = [pd.datetime, float, float]\n",
    "\n",
    "##SET SEABORN STYLE\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "##SET MATPLOTLIB STYLE\n",
    "TICKS_FONTSIZE = 16\n",
    "LABEL_FONTSIZE=18\n",
    "LEGEND_FONTSIZE=15\n",
    "linestyles = (':','-','.','--')\n",
    "\n",
    "mpl.rcParams['xtick.labelsize'] = TICKS_FONTSIZE \n",
    "mpl.rcParams['ytick.labelsize'] = TICKS_FONTSIZE\n",
    "mpl.rcParams['legend.fontsize'] = TICKS_FONTSIZE\n",
    "mpl.rcParams['axes.labelsize'] = LABEL_FONTSIZE\n",
    "mpl.rcParams['axes.titlesize'] = LABEL_FONTSIZE\n",
    "mpl.rcParams['font.size'] = LABEL_FONTSIZE\n",
    "plt.rc('legend',**{'fontsize':LEGEND_FONTSIZE})\n",
    "\n",
    "\n",
    "#Read input files from the directory and returns DataTable object in a combined list\n",
    "def read_inputs(flag):\n",
    "    #Get list of nodes(files) with results\n",
    "    INPUT_DIR = os.path.join( os.getcwd(), EXP_NAME)\n",
    "    dirs = [f for f in os.listdir(INPUT_DIR) if os.path.isdir(os.path.join(INPUT_DIR, f))]\n",
    "    #Load results from each node\n",
    "    nodes_results = {}\n",
    "    for sub_dir in dirs:\n",
    "        nodes = [f for f in os.listdir(INPUT_DIR+'/'+sub_dir) if os.path.isfile(os.path.join(INPUT_DIR+'/'+sub_dir, f))]\n",
    "        for node in nodes:\n",
    "            file =''\n",
    "            #if flag == 0 & node.endswith('0.log'):\n",
    "            #    file == os.path.join(INPUT_DIR+'/'+sub_dir,node)\n",
    "            #elif flag == 1 & node.endswith('1.log'):\n",
    "            #    file = os.path.join(INPUT_DIR+'/'+sub_dir,node)\n",
    "            #elif flag == 2:\n",
    "            file = os.path.join(INPUT_DIR+'/'+sub_dir,node)\n",
    "            #print('reading:', file)\n",
    "            #else:\n",
    "            #    continue\n",
    "            try:\n",
    "                temp = pd.read_csv(file, sep=' ', header=None, usecols=[0,1,4])\n",
    "                temp.columns = headers\n",
    "                temp['time'] = pd.to_datetime(temp['time'], unit='s')\n",
    "                temp.set_index('time')\n",
    "                if sub_dir in nodes_results:\n",
    "                    nodes_results[sub_dir] = pd.concat([nodes_results[sub_dir], temp])\n",
    "                else:\n",
    "                    nodes_results[sub_dir] = temp                    \n",
    "            except Exception:\n",
    "                print(node, 'EXception')\n",
    "    return nodes_results\n",
    "\n",
    "\n",
    "    \n",
    "nodes_all = read_inputs(2)\n",
    "    #nodes_even = read_inputs(0)\n",
    "    #nodes_odd = read_inputs(1)\n",
    "    #plot_bytes_per_day(nodes_all,'bytes')\n",
    "    #plot_request_numbers(nodes_all,'bytes')\n",
    "    #plot_hourly_request_number(nodes_all,'bytes')\n",
    "    #plot_bytes_per_second(nodes_all,'bytes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_bytes_per_day(results, var):\n",
    "    \n",
    "    \n",
    "    #labels = []\n",
    "    #for key in results:\n",
    "    df = results['3982']\n",
    "    df = df.set_index(df.time)        \n",
    "    df_sample = df.resample('240Min').sum()        \n",
    "    df_sample[(var)].plot(logy=True)        \n",
    "    #labels.append(key)\n",
    "    #plt.legend(labels)\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Bytes')\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "def plot_request_numbers(results, var):\n",
    "    labels =[]\n",
    "    for key in results:\n",
    "        df = results[key]\n",
    "        df = df.set_index(df.time)        \n",
    "        ecdf = getECDF(df,'bytes')\n",
    "        labels.append(key)\n",
    "        ecdf.plot()\n",
    "    plt.legend(labels)\n",
    "    plt.xlim(0, 10000)\n",
    "    plt.xlabel('Request size (bytes)')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_hourly_request_size(results,var):  \n",
    "    labels = []\n",
    "    for key in results:\n",
    "        df = results[key]\n",
    "        df = df.set_index(pd.DatetimeIndex(df.time))\n",
    "        df_sample = df.resample('60Min').mean()\n",
    "        ecdf = getECDF(df_sample, var)\n",
    "        ax = ecdf.plot(logx=True)\n",
    "        labels.append(key)\n",
    "    plt.legend(labels)\n",
    "    plt.xlabel('Hourly request size (bytes)')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_hourly_request_number(results, var):\n",
    "    labels = []\n",
    "    for key in results:\n",
    "        df = results[key]\n",
    "        df = df.set_index(pd.DatetimeIndex(df.time))\n",
    "        df_sample = df.resample('60Min').count()\n",
    "        ecdf = getECDF(df_sample, var)\n",
    "        labels.append(key)\n",
    "        ecdf.plot()\n",
    "    plt.legend(labels)\n",
    "    #plt.xlim(0,10000)\n",
    "    plt.xlabel('Number of hourly request')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_bytes_per_second(results,var):\n",
    "    labels = []\n",
    "    for key in results:\n",
    "        df = results[key]\n",
    "        df = df.set_index(pd.DatetimeIndex(df.time))\n",
    "        df = df[(df['elapsed']>0) & df['bytes']>0 ]\n",
    "        df['bytes_second'] = df['bytes']/df['elapsed']\n",
    "        df['bytes_second'] = df['bytes_second']*1000\n",
    "        #df[('bytes_second')].plot()\n",
    "        labels.append(key)\n",
    "        ecdf = getECDF(df, 'bytes_second')\n",
    "        ecdf.plot(logx=True)\n",
    "    plt.legend(labels)\n",
    "    plt.xlabel('Request processing throughput bytes/sec')\n",
    "    plt.show()\n",
    "\n",
    "def getECDF(df, var):\n",
    "    \"\"\"Helper function that caclulates the ECDF of a dataframe\"\"\"\n",
    "    df = df[var].value_counts()\n",
    "    ecdf = df.sort_index().cumsum()*1./df.sum()\n",
    "    return ecdf\n",
    "    \n",
    "#plot_bytes_per_day(nodes_all,'bytes')\n",
    "#plot_request_numbers(nodes_all,'bytes')\n",
    "#plot_hourly_request_number(nodes_all,'bytes')\n",
    "#plot_hourly_request_size(nodes_all,'bytes')\n",
    "plot_bytes_per_second(nodes_all,'bytes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
